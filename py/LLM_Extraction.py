import os
import re
import json
import openai
import faiss
import numpy as np
from datetime import datetime
from Methods import *
openai.api_key = "sk-3fk05T3Cme02GzUGBc56BaBfA7Ff4dCa9d7dE5AeA689913c"

openai.base_url = "https://api.gpt.ge/v1/"
openai.default_headers = {"x-foo": "true"}

# ===== 1. åˆå§‹åŒ–å‘é‡æ•°æ®åº“ï¼ˆFAISSï¼‰ =====
dimension = 1536  # OpenAI text-embedding-3-small è¾“å‡ºå‘é‡ç»´åº¦
index = faiss.IndexFlatL2(dimension)  # L2 è·ç¦»ç´¢å¼•

def llm_extract_information_incremental(new_sentence, existing_topics=None): 
    
    """
    å¯¹æ–°å¥å­è¿›è¡Œä¸»é¢˜æŠ½å–ï¼Œå¹¶ä¸å·²æœ‰æŠ½å–ç»“æœåˆå¹¶
    """
    existing_topics = existing_topics or []

    # ğŸ‘‰ æ”¯æŒ dict æˆ– str
    if isinstance(new_sentence, dict):
        sentence_text = new_sentence.get("content", "")
    else:
        sentence_text = str(new_sentence)

    prompt = f"""è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

        ä»»åŠ¡ï¼šé¦–å…ˆä½ éœ€è¦å°†æ–°çš„ä¸€å¥å¯¹è¯ä¸­æ— å…³ç´§è¦çš„ä¿¡æ¯è¿›è¡Œè¿‡æ»¤ï¼Œç„¶åå¯¹è¿™å¥å¯¹è¯è¿›è¡Œä¸»é¢˜æŠ½å–ã€‚
        å¥å­: {sentence_text}
        å·²æœ‰ä¸»é¢˜: {json.dumps(existing_topics, ensure_ascii=False)}
        è¯·åªè¾“å‡ºæ–°å¥å­çš„ä¸»é¢˜ JSONï¼Œä¸ä¿®æ”¹å·²æœ‰ä¸»é¢˜ã€‚

        è¾“å‡ºè¦æ±‚ï¼š
        1. è¾“å‡ºå¿…é¡»æ˜¯æ ‡å‡† JSON å¯¹è±¡ï¼Œä¸¥ç¦åŒ…å«ä»£ç å—æ ‡è®°ï¼ˆå¦‚```jsonï¼‰æˆ–å¤šä½™æ–‡å­—ã€‚
        2. æ¯ä¸ªä¸»é¢˜åŒ…å«å­—æ®µï¼š
        - "topic": ä¸»é¢˜åç§°ï¼ˆæœ€é«˜å±‚é¢†åŸŸåï¼Œå¦‚â€œäººå·¥æ™ºèƒ½â€â€œå¯è§†åŒ–â€â€œæ™ºæ…§åŸå¸‚â€ï¼‰ï¼Œä¸ºåè¯çŸ­è¯­ã€‚
        - "slots": ä¸€ä¸ªæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {{ "sentence": åŸå§‹å¥å­, "slot": å¯¹åº”çš„å­ä¸»é¢˜}}
        3. slotå¿…é¡»æ˜¯**ç®€æ´ã€å…·ä½“ã€å¯è½åœ°çš„åè¯çŸ­è¯­æˆ–åŠ¨å®¾çŸ­è¯­**ï¼Œèƒ½æŒ‡å‘ä¸€ä¸ªæ¸…æ™°çš„å…³æ³¨ç‚¹ã€‚
        4. ä¿æŒä¸»é¢˜ä¸å­ä¸»é¢˜è¡¨è¿°ç®€æ´ã€‚
        5. è¾“å‡ºçš„æ ‡å‡† JSON æ ¼å¼ï¼š
        [
            {{
                "topic": "ä¸»é¢˜åç§°",
                "slots": [
                    {{"sentence": "åŸå§‹å¥å­", "slot": "å­ä¸»é¢˜"}}
                ]
            }}
        ]
        ä¾‹å­ï¼š
        [
            {{
                "topic": "äººå·¥æ™ºèƒ½",
                "slots": [
                    {{"sentence": "äººå·¥æ™ºèƒ½ä¼¦ç†å…³æ³¨çš„ä¸ä»…æ˜¯ç®—æ³•çš„å…¬å¹³æ€§ä¸éšç§ä¿æŠ¤ï¼Œè¿˜åŒ…æ‹¬æ•°æ®ä½¿ç”¨çš„é€æ˜åº¦ã€æ¨¡å‹å†³ç­–çš„å¯è§£é‡Šæ€§ã€‚", "slot": "äººå·¥æ™ºèƒ½ä¼¦ç†"}}
                ]
            }}
        ]


        è§„åˆ™è¡¥å……ï¼š
        1. æ‰€æœ‰é—®é¢˜é¦–å…ˆè¦è¯†åˆ«æœ€é«˜å±‚çš„å¤§ä¸»é¢˜ï¼Œä½œä¸ºå”¯ä¸€çš„topicã€‚
        2. è‹¥å¥å­æ¶‰åŠå¤šä¸ªå†…å®¹ï¼Œè¯·æç‚¼å‡ºæœ€æ ¸å¿ƒçš„ä¸»é¢˜ã€‚
        3. ä¸å…è®¸æ¯ä¸ªå­å¥éƒ½å•ç‹¬æˆä¸ºä¸€ä¸ª slotã€‚
        4. slot **ç¦æ­¢**ç©ºæ³›/ç¬¼ç»Ÿ/æŠ½è±¡æŒ‡ä»£ï¼Œä¾‹å¦‚åªå†™â€œç ”ç©¶â€â€œé—®é¢˜â€â€œåº”ç”¨â€â€œæ–¹æ³•è®ºâ€â€œå½±å“â€â€œå‘å±•â€â€œç°çŠ¶â€â€œè®¨è®ºâ€ç­‰æ³›è¯ã€‚
        5. topicåªè¡¨ç¤ºæ ¸å¿ƒé¢†åŸŸï¼Œslots è´Ÿè´£ç»†åˆ†é—®é¢˜ã€‚
        """
    
    completion = openai.chat.completions.create(
        model="gpt-4o",
        temperature=0.5,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€åå¯¹è¯åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»å¯¹è¯ä¸­æå–å‡ºç”¨æˆ·çš„å¯¹è¯ä¸»é¢˜å¹¶åˆå¹¶åˆ°å·²æœ‰ä¸»é¢˜ã€‚"},
            {"role": "user", "content": prompt }
            ],)
    
    try:
        result = json.loads(completion.choices[0].message.content)
    except json.JSONDecodeError:
        result = []

    print("æŠ½å–ç»“æœï¼š")
    print(result)

    return result

# ç”Ÿæˆ embedding
def get_embedding(text):
    emb = openai.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return np.array(emb.data[0].embedding, dtype="float32")

# ===== åˆå§‹åŒ– Memoryï¼ˆå¯ä»¥æ¢æˆæ•°æ®åº“ï¼‰ =====
user_memory_db = {}  # ç¤ºä¾‹: {user_id: {key: value}}

# ===== Memoryæ“ä½œå‡½æ•° =====
# å¾—åˆ°ç”¨æˆ·Memory
def get_user_memory(user_id):
    """
    è¿”å›æ•´ç†å¥½çš„æ–‡æœ¬ï¼Œç”¨äºæ‹¼æ¥åˆ°prompt
    """
    if user_id not in user_memory_db:
        return ""
    memory = user_memory_db[user_id]
    return "\n".join([f"{k}: {v}" for k, v in memory.items()])

# æ›´æ–°ç”¨æˆ·Memory
def update_user_memory(user_id, key, value):
    global user_memory_db
    if user_id not in user_memory_db:
        user_memory_db[user_id] = {}
    
    # å¦‚æœ key å·²å­˜åœ¨ï¼Œåšâ€œè¿½åŠ â€è€Œä¸æ˜¯è¦†ç›–
    if key in user_memory_db[user_id]:
        old_value = user_memory_db[user_id][key]
        if value not in old_value:
            user_memory_db[user_id][key] = f"{old_value}; {value}"
    else:
        user_memory_db[user_id][key] = value
    
    user_memory_db[user_id]['last_updated'] = str(datetime.now())

    print(f"Memoryæ›´æ–°ï¼š{user_id} - {key} - {value}")
    print("Memoryåº“:" ,user_memory_db)

def extract_memory_from_text(user_id, new_sentence):
    """
    è°ƒç”¨ GPT è‡ªåŠ¨ä»æ–‡æœ¬ä¸­æŠ½å–å…³é”®ä¿¡æ¯ï¼ˆå¦‚åå­—ã€å…´è¶£ã€åå¥½ç­‰ï¼‰
    å¹¶æ›´æ–° Memory
    """
    prompt = f"""
    è¯·ä»ä¸‹é¢çš„æ–‡æœ¬ä¸­æå–ç”¨æˆ·å¯èƒ½æƒ³è®°ä½çš„å…³é”®ä¿¡æ¯ï¼ŒåŒ…æ‹¬å§“åã€å…´è¶£ã€çˆ±å¥½ã€å­¦ä¹ ç›®æ ‡ç­‰ã€‚
    è¾“å‡ºå¿…é¡»æ˜¯æ ‡å‡† JSON å¯¹è±¡ï¼Œä¸¥ç¦åŒ…å«ä»£ç å—æ ‡è®°ï¼ˆå¦‚```jsonï¼‰æˆ–å¤šä½™æ–‡å­—ï¼Œé”®åéšæ„ä½†è¦èƒ½æè¿°ä¿¡æ¯ï¼Œå¦‚ï¼š
    {{
        "name": "Alice",
        "favorite_language": "Python"
    }}

    æ–‡æœ¬å†…å®¹ï¼š
    {new_sentence}
    """

    completion = openai.chat.completions.create(
        model="gpt-4o",
        temperature=0,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€åä¿¡æ¯æŠ½å–åŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    result = (completion.choices[0].message.content)
    # æ›´æ–°è§£æç»“æœåˆ°Memory
    try:
        memory_data = json.loads(result)
        for key, value in memory_data.items():
            update_user_memory(user_id, key, value)
    except json.JSONDecodeError:
        # å‡ºç°è§£æé”™è¯¯æ—¶å¯ä»¥å¿½ç•¥æˆ–è®°å½•æ—¥å¿—
        print("Memory JSONè§£æå¤±è´¥:", result)

# ===== GPT + Memory + RAGå‡½æ•° =====
def talk_to_chatbot(user_id, content, source, history_msgs, top_k=3):
    """
    content: æœ¬è½®ç”¨æˆ·é—®é¢˜
    source: æ¶ˆæ¯æ¥æºï¼Œå¯ä¼ å…¥
    history_msgs: çŸ­æœŸå¯¹è¯åˆ—è¡¨ [{"role": "user"/"assistant", "content": "..."}]
    index: FAISS ç´¢å¼•å¯¹è±¡ï¼Œç”¨äºå­˜å‚¨é•¿æœŸè®°å¿†
    top_k: RAG æ£€ç´¢æ•°é‡
    """
    global index

    # 1. å…ˆæ£€ç´¢Memory
    memory_context = get_user_memory(user_id)

    # 2. ä¸ºç”¨æˆ·è¾“å…¥ç”Ÿæˆ embedding
    query_emb = get_embedding(content).reshape(1, -1)

    # 3. æ£€ç´¢ç›¸å…³ Memory
    related_context = ""
    if index is not None and memory_context:
        D, I = index.search(query_emb, top_k)
        # ç®€å•ç¤ºä¾‹ï¼šç”¨ç´¢å¼•å¯¹åº”çš„ Memory è¡Œï¼ˆå‡è®¾ memory_text åˆ†è¡Œå­˜å‚¨ï¼‰
        memory_lines = memory_context.split("\n")
        related_context = "\n".join([memory_lines[i] for i in I[0] if i < len(memory_lines)])

    # 4.å…ˆæŠŠå†å²å¯¹è¯æ•´ç†æˆæ–‡æœ¬
    history_text = "\n".join(
    [f"{msg.get('from', 'user').capitalize()}: {msg.get('text', '')}" for msg in history_msgs])

    # 5. ç»„ç»‡ promptï¼ŒæŠŠ Memory å’Œ RAG æ£€ç´¢å†…å®¹éƒ½æ‹¼è¿›å»
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€åå¯¹è¯åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä¸ç”¨æˆ·è¿›è¡Œæ²Ÿé€š, è¯·æ ¹æ®ç”¨æˆ·çš„è¾“å…¥ï¼Œåˆç†å›ç­”ï¼Œå¹¶ä¿æŒæ²Ÿé€šè¿è´¯ã€‚"},
        {"role": "user", "content": f"""
        ä¸‹é¢æ˜¯ä¸æœ¬é—®é¢˜ç›¸å…³çš„å†å²å¯¹è¯ï¼š{history_text}
        ç”¨æˆ·ä¿¡æ¯ï¼š
        {memory_context}
        ç›¸å…³ Memory æ£€ç´¢å†…å®¹ï¼š
        {related_context}
        ç°åœ¨ç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼š
        {content}"""}
        ]
    
    # 6. è°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆå›å¤ 
    completion = openai.chat.completions.create(
        model="gpt-4o",
        temperature=0.5,
        messages=messages,
        )
    result = (completion.choices[0].message.content)

    # 7. æ›´æ–° Memoryï¼ˆé•¿æœŸè®°å¿†ï¼‰åˆ° FAISS
    if index is not None and memory_context:
        memory_text = "\n".join([f"{k}: {v}" for k, v in user_memory_db[user_id].items()])
        emb = get_embedding(memory_text).reshape(1, -1)
        index.add(emb)

    # 8. è‡ªåŠ¨æŠ½å–æœ€æ–° Memory ä¿¡æ¯
    extract_memory_from_text(user_id, content)

    return result

def create_theme_variables(result_dict):
    for theme, questions in result_dict.items():
        # åˆ›å»ºåˆæ³•å˜é‡åï¼ˆç§»é™¤éæ³•å­—ç¬¦ï¼‰
        var_name = theme.replace(" ", "_").replace("ï¼š", "").replace("-", "_")
        globals()[var_name] = questions
    
    print(f"{var_name} = {questions}")  # å¯é€‰ï¼šæ‰“å°å‡ºæ¥
