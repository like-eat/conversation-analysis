import os
import re
import json
import openai
import faiss
import numpy as np
from datetime import datetime
from Methods import *
openai.api_key = "sk-3fk05T3Cme02GzUGBc56BaBfA7Ff4dCa9d7dE5AeA689913c"

openai.base_url = "https://api.gpt.ge/v1/"
openai.default_headers = {"x-foo": "true"}


with open('py/conversation_example/ChatGPT.txt', 'r', encoding='utf-8') as file:
    content = file.read()
    # print(content)

# ===== 1. åˆå§‹åŒ–å‘é‡æ•°æ®åº“ï¼ˆFAISSï¼‰ =====
dimension = 1536  # OpenAI text-embedding-3-small è¾“å‡ºå‘é‡ç»´åº¦
index = faiss.IndexFlatL2(dimension)  # L2 è·ç¦»ç´¢å¼•
# å®šä¹‰å…¨å±€æ¶ˆæ¯åˆ—è¡¨ï¼ˆä¿å­˜ä¸Šä¸‹æ–‡ï¼‰
history = []

def llm_extract_information_incremental(new_sentence, existing_domains=None): 
    
    """
    å¯¹æ–°å¥å­è¿›è¡Œä¸»é¢˜æŠ½å–ï¼Œå¹¶ä¸Žå·²æœ‰æŠ½å–ç»“æžœåˆå¹¶
    """
    existing_domains = existing_domains or []

    # ðŸ‘‰ æ”¯æŒ dict æˆ– str
    if isinstance(new_sentence, dict):
        sentence_text = new_sentence.get("content", "")
    else:
        sentence_text = str(new_sentence)

    prompt = f"""è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

        ä»»åŠ¡ï¼šå¯¹ä¸€å¥æ–°çš„å¯¹è¯è¿›è¡Œä¸»é¢˜æŠ½å–ï¼Œåªå¤„ç†è¿™å¥è¯ï¼Œä¸é‡æ–°æŠ½å–å·²æœ‰ä¸»é¢˜ã€‚
        æ–°å¥å­: {sentence_text}
        å·²æœ‰ä¸»é¢˜: {json.dumps(existing_domains, ensure_ascii=False)}
        è¯·åªè¾“å‡ºæ–°å¥å­çš„ä¸»é¢˜ JSONï¼Œä¸ä¿®æ”¹å·²æœ‰ä¸»é¢˜ã€‚

        è¾“å‡ºè¦æ±‚ï¼š
        1. è¾“å‡ºå¿…é¡»æ˜¯æ ‡å‡† JSON å¯¹è±¡ï¼Œä¸¥ç¦åŒ…å«ä»£ç å—æ ‡è®°ï¼ˆå¦‚```jsonï¼‰æˆ–å¤šä½™æ–‡å­—ã€‚
        2. æ¯ä¸ªä¸»é¢˜åŒ…å«å­—æ®µï¼š
        - "domain": ä¸»é¢˜åç§°
        - "slots": ä¸€ä¸ªæ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {{ "sentence": åŽŸå§‹å¥å­, "slot": å¯¹åº”çš„å­ä¸»é¢˜}}
        3. **slots åªèƒ½æŠ½å– 1 ä¸ª**ï¼Œåªä¿ç•™æœ€æ ¸å¿ƒã€æœ€å…·ä»£è¡¨æ€§çš„å­ä¸»é¢˜ã€‚
        4. ä¿æŒä¸»é¢˜ä¸Žå­ä¸»é¢˜è¡¨è¿°ç®€æ´ï¼Œä¸è¶…è¿‡ 6 ä¸ªå­—ã€‚
        5. slots å¿…é¡»æ˜¯ã€Œæ¦‚å¿µçº§åˆ«ã€æˆ–ã€Œè®®é¢˜çº§åˆ«ã€çš„å…³é”®è¯ï¼Œè€Œä¸æ˜¯æ¯ä¸ªå­å¥ã€‚
        6. è¾“å‡ºçš„æ ‡å‡† JSON æ ¼å¼ï¼š
        [
            {{
                "domain": "ä¸»é¢˜åç§°",
                "slots": [
                    {{"sentence": "åŽŸå§‹å¥å­", "slot": "å­ä¸»é¢˜"}}
                ]
            }}
        ]

        è§„åˆ™è¡¥å……ï¼š
        1. æ‰€æœ‰é—®é¢˜é¦–å…ˆè¦è¯†åˆ«æœ€é«˜å±‚çš„å¤§ä¸»é¢˜ï¼ˆå¦‚â€œå¯è§†åŒ–â€ï¼‰ï¼Œä½œä¸ºå”¯ä¸€çš„ domainã€‚
        2. è‹¥å¥å­æ¶‰åŠå¤šä¸ªå†…å®¹ï¼Œè¯·æç‚¼å‡ºæœ€æ ¸å¿ƒçš„ä¸»é¢˜ã€‚
        3. ä¸å…è®¸æ¯ä¸ªå­å¥éƒ½å•ç‹¬æˆä¸ºä¸€ä¸ª slotã€‚
        4. slot åº”è¯¥æ˜¯â€œè¯¥ä¸»é¢˜ä¸‹çš„æ ¸å¿ƒç‚¹â€â€”â€”ä¾‹å¦‚æ–¹æ³•ã€åº”ç”¨ã€é—®é¢˜ã€æŒ‘æˆ˜ã€è¯„ä»·ç­‰ï¼›
        5. domain åªè¡¨ç¤ºæ ¸å¿ƒé¢†åŸŸï¼Œä¸è¶…è¿‡ 6 ä¸ªå­—ï¼›slots è´Ÿè´£ç»†åˆ†é—®é¢˜ã€‚
        """
    
    completion = openai.chat.completions.create(
        model="gpt-4o",
        temperature=0.5,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€åå¯¹è¯åˆ†æžåŠ©æ‰‹ï¼Œæ“…é•¿ä»Žå¯¹è¯ä¸­æå–å‡ºç”¨æˆ·çš„å¯¹è¯ä¸»é¢˜å¹¶åˆå¹¶åˆ°å·²æœ‰ä¸»é¢˜ã€‚"},
            {"role": "user", "content": prompt }
            ],)
    
    try:
        result = json.loads(completion.choices[0].message.content)
    except json.JSONDecodeError:
        result = []

    print("æŠ½å–ç»“æžœï¼š")
    print(result)

    return result

# ç”Ÿæˆ embedding
def get_embedding(text):
    emb = openai.embeddings.create(
        model="text-embedding-3-small",
        input=text
    )
    return np.array(emb.data[0].embedding, dtype="float32")

# ===== åˆå§‹åŒ– Memoryï¼ˆå¯ä»¥æ¢æˆæ•°æ®åº“ï¼‰ =====
user_memory_db = {}  # ç¤ºä¾‹: {user_id: {key: value}}

# ===== Memoryæ“ä½œå‡½æ•° =====
# å¾—åˆ°ç”¨æˆ·Memory
def get_user_memory(user_id):
    """
    è¿”å›žæ•´ç†å¥½çš„æ–‡æœ¬ï¼Œç”¨äºŽæ‹¼æŽ¥åˆ°prompt
    """
    if user_id not in user_memory_db:
        return ""
    memory = user_memory_db[user_id]
    return "\n".join([f"{k}: {v}" for k, v in memory.items()])

# æ›´æ–°ç”¨æˆ·Memory
def update_user_memory(user_id, key, value):
    global user_memory_db
    if user_id not in user_memory_db:
        user_memory_db[user_id] = {}
    
    # å¦‚æžœ key å·²å­˜åœ¨ï¼Œåšâ€œè¿½åŠ â€è€Œä¸æ˜¯è¦†ç›–
    if key in user_memory_db[user_id]:
        old_value = user_memory_db[user_id][key]
        if value not in old_value:
            user_memory_db[user_id][key] = f"{old_value}; {value}"
    else:
        user_memory_db[user_id][key] = value
    
    user_memory_db[user_id]['last_updated'] = str(datetime.now())

    print(f"Memoryæ›´æ–°ï¼š{user_id} - {key} - {value}")
    print("Memoryåº“:" ,user_memory_db)

def extract_memory_from_text(user_id, new_sentence):
    """
    è°ƒç”¨ GPT è‡ªåŠ¨ä»Žæ–‡æœ¬ä¸­æŠ½å–å…³é”®ä¿¡æ¯ï¼ˆå¦‚åå­—ã€å…´è¶£ã€åå¥½ç­‰ï¼‰
    å¹¶æ›´æ–° Memory
    """
    prompt = f"""
    è¯·ä»Žä¸‹é¢çš„æ–‡æœ¬ä¸­æå–ç”¨æˆ·å¯èƒ½æƒ³è®°ä½çš„å…³é”®ä¿¡æ¯ï¼ŒåŒ…æ‹¬å§“åã€å…´è¶£ã€çˆ±å¥½ã€å­¦ä¹ ç›®æ ‡ç­‰ã€‚
    è¾“å‡ºå¿…é¡»æ˜¯æ ‡å‡† JSON å¯¹è±¡ï¼Œä¸¥ç¦åŒ…å«ä»£ç å—æ ‡è®°ï¼ˆå¦‚```jsonï¼‰æˆ–å¤šä½™æ–‡å­—ï¼Œé”®åéšæ„ä½†è¦èƒ½æè¿°ä¿¡æ¯ï¼Œå¦‚ï¼š
    {{
        "name": "Alice",
        "favorite_language": "Python"
    }}

    æ–‡æœ¬å†…å®¹ï¼š
    {new_sentence}
    """

    completion = openai.chat.completions.create(
        model="gpt-4o",
        temperature=0,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€åä¿¡æ¯æŠ½å–åŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ]
    )
    result = (completion.choices[0].message.content)
    # æ›´æ–°è§£æžç»“æžœåˆ°Memory
    try:
        memory_data = json.loads(result)
        for key, value in memory_data.items():
            update_user_memory(user_id, key, value)
    except json.JSONDecodeError:
        # å‡ºçŽ°è§£æžé”™è¯¯æ—¶å¯ä»¥å¿½ç•¥æˆ–è®°å½•æ—¥å¿—
        print("Memory JSONè§£æžå¤±è´¥:", result)

# ===== GPT + Memory + RAGå‡½æ•° =====
def talk_to_chatbot(user_id, content, top_k=3):
    global history, index

    # 1. å…ˆæ£€ç´¢Memory
    memory_context = get_user_memory(user_id)

    # 2. ä¸ºç”¨æˆ·è¾“å…¥ç”Ÿæˆ embedding
    query_emb = get_embedding(content).reshape(1, -1)

    # æ£€ç´¢ç›¸ä¼¼åŽ†å²related_context
    if len(history) > 0:
        D, I = index.search(query_emb, top_k)
        related_context = "\n".join([history[i] for i in I[0] if i < len(history)])
    else:
        related_context = ""

    # 3. ç»„ç»‡ promptï¼ŒæŠŠ Memory å’Œ RAG æ£€ç´¢å†…å®¹éƒ½æ‹¼è¿›åŽ»
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€åå¯¹è¯åˆ†æžåŠ©æ‰‹ï¼Œæ“…é•¿ä¸Žç”¨æˆ·è¿›è¡Œæ²Ÿé€š, è¯·æ ¹æ®ç”¨æˆ·çš„è¾“å…¥ï¼Œåˆç†å›žç­”ï¼Œå¹¶ä¿æŒæ²Ÿé€šè¿žè´¯ã€‚"},
        {"role": "user", "content": f"""
        ä¸‹é¢æ˜¯ä¸Žæœ¬é—®é¢˜ç›¸å…³çš„åŽ†å²å¯¹è¯ï¼š{related_context}
        ç”¨æˆ·ä¿¡æ¯ï¼š
        {memory_context}
        çŽ°åœ¨ç”¨æˆ·çš„é—®é¢˜æ˜¯ï¼š
        {content}"""}
        ]
    # 4. è°ƒç”¨å¤§æ¨¡åž‹ç”Ÿæˆå›žå¤ 

    completion = openai.chat.completions.create(
        model="gpt-4o",
        temperature=0.5,
        messages=messages,
        )
    result = (completion.choices[0].message.content)

    # 5. æ›´æ–° FAISS å‘é‡æ•°æ®åº“ï¼ˆå­˜ç”¨æˆ·é—®é¢˜å³å¯ï¼Œä¹Ÿå¯å­˜æ¨¡åž‹å›žç­”ï¼‰
    for text in [content, result]:  # ä½ è¦æ˜¯åªæƒ³å­˜ç”¨æˆ·é—®é¢˜ï¼Œå¯ä»¥åŽ»æŽ‰ result
        emb = get_embedding(text).reshape(1, -1)
        index.add(emb)
        history.append(text)

    # 6. è‡ªåŠ¨ä»Žç”¨æˆ·è¾“å…¥å’Œæ¨¡åž‹å›žç­”æŠ½å– Memory ä¿¡æ¯
    extract_memory_from_text(user_id, content)  # ä»Žç”¨æˆ·è¾“å…¥ä¸­æå–

    return result

def create_theme_variables(result_dict):
    for theme, questions in result_dict.items():
        # åˆ›å»ºåˆæ³•å˜é‡åï¼ˆç§»é™¤éžæ³•å­—ç¬¦ï¼‰
        var_name = theme.replace(" ", "_").replace("ï¼š", "").replace("-", "_")
        globals()[var_name] = questions
    
    print(f"{var_name} = {questions}")  # å¯é€‰ï¼šæ‰“å°å‡ºæ¥
