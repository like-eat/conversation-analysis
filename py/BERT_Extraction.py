from bertopic import BERTopic
from umap import UMAP
from hdbscan import HDBSCAN
from sklearn.feature_extraction.text import CountVectorizer
import jieba

# jieba 分词器
def jieba_tokenizer(text):
    return jieba.lcut(text)

def bertopic_extraction_information(docs, keep_noise=False):

    # CountVectorizer + jieba
    vectorizer_model = CountVectorizer(tokenizer=jieba_tokenizer, min_df=1)

    # 调整 UMAP 参数（适合小数据集）
    umap_model = UMAP(n_neighbors=2, n_components=5, min_dist=0.1, metric="cosine", random_state=42)
    hdbscan_model = HDBSCAN(min_cluster_size=2)
    # BERTopic
    topic_model = BERTopic(
        umap_model=umap_model,
        vectorizer_model=vectorizer_model,
        language="chinese (simplified)",
        min_topic_size=1,  # 保留单条文档也能成主题
        hdbscan_model=hdbscan_model  # 让 BERTopic 内部自动处理，不显式传 HDBSCAN
    )

    topics, probs = topic_model.fit_transform(docs)

    result = []

    for topic_id in topic_model.get_topic_info()["Topic"]:

        # 该主题对应的原始句子（保持顺序）
        sentences = [doc for doc, t in zip(docs, topics) if t == topic_id]

        result.append({
            "topic_id": topic_id,
            "sentences": sentences
        })
    
    return result


if __name__ == "__main__":
    docs = ['DST是什么', '对话状态跟踪可以应用到长对话分析中吗', 'DST可以和LLM结合起来吗', 'DST格式是什么', 'DST格式类似于树结构吗，domain是父节点，每个slot 是一个子节点', 'slot里面会有多个值吗', '我可以使用一些子模型与LLM相配合吗，例如主题提取，任务识别这种子模型', '如果我的方法使用了LLM和子模型还有DST，那整个过程是什么样的', '子模型在LLM抽取之前使用吗？', '如果我是想对长 对话当中的关键信息抽取，子模型在哪里使用会比较好', '给我个例子，说明子模 型是如何筛选的，一个长对话的例子', '这个例子中，子模型输入到LLM当中的内容是什么', '大模型会输出什么', '大模型输出给DST的内容是什么', '所以LLM输出 给DST的内容就已经是DST格式的了吗？', 'slot里面会有多个值吗', '我想让你帮 我模拟生成一段长对话，总体对话轮数在30-50轮左右，场景是用户提问，大模型回复（回复不需要太长）。总体主题主要有四个主题，排序算法（有哪些，快速排序 适用于什么场景）。聚类算法（聚类算法有哪些，写一个K-means算法代码，如何将K-means算法效果呈现出来）。vegalite（vgealite是前端可视化库吗，用vegalite写一个条形图）。长对话分析（方法有哪些，DST可以用于长对话分析吗，长对话分析可以与可视化结合在一起吗）。', '我想你帮我把这段模拟对话当中的关键信息 都抽取出来，例如主题，任务，问题。', '你帮我把上面那段模拟对话的轮数取消 ，然后重新生成一边，像是正常的对话', '论文当中的pipeline代表什么', '大模 型有遗忘机制吗，例如我跟你聊了A,B两件事，然后我会说让你忘记B，我们继续聊A。', '可以支持上下文截断吗', '长对话在会议记录当中有什么作用', '你觉得人 们日常会聊哪些话题呢', '你能帮我生成一段30到50轮的对话吗，分别是用户和大 模型的聊天，大模型的回复尽量简短。聊的内容主要是日常生活，内容包含四个主 题分别是：工作上面（上课情况，考试情况），生活琐事（天气，健康，吃喝）， 要不要读研方面， 运动方面（足球，篮球，排球）', '把U改成用户，AI改成大模 型', '你帮我把主题和任务抽取一下，说明轮数', '在帮我扩充一点吧，到60轮', '对这段话进行主题抽取', '这些主题能转换成DST格式吗，', '将每个domain，slots，value都展示出来', '这段对话传入到小模型（主题模型）当中会将对话的主题抽取出来吗', '那我将小模型抽取出的结果传入到LLM当中，让其将对话中的关键信息抽取出来，LLM会抽出来什么', '小模型其实并没有将关键的具体信息或者任务抽取出来，只是处理了无关紧要的对话吗', '你觉得读研和学业这两个主题是不是有 点接近，能不能把读研换一个别的话题', '旅行吧', '现在将对话的主题给我转换 成DST格式', '把这60轮对话完整的给我发一下', '介绍一下什么是DST', '介绍一 下DST格式是什么', '我想你帮我修改一下这段话：', '这段话也帮我修改一下：', '这段话给我改写一下，我思路改变了： 具体而言，该方法首先使用大语言模型结合定制Prompt，从对话中识别并抽取参与者、对话主题、提出的问题、发布的任务 以及对应时间轴等结构化信息。在抽取出的主题信息基础上，再应用主题模型对对 话主题进行建模与分类，从而获得各主题下的问题层级关系。最终形成树形结构表 示：每个主题为父节点，其下的子节点按问题逻辑顺序或语义递进排列，例如“聚类算法”为父节点，“什么是聚类算法”为第二层子节点，“K-means算法是聚类算法吗” 为第三层子节点。该结构能够直观呈现长对话中主题与问题的层次关系，并有效捕 捉隐含问题和上下文依赖。 我首先是使用小模型（主题模型）对长对话进行筛选，过滤掉无关紧要的对话，然后使用LLM结合Prompt根据我的需求将关键信息抽取出来，然后将输出转换成DST多层结构', '“长对话是指由多轮、多阶段交互组成的对话 形式。目前，长对话广泛应用于多个场景，包括 AI 聊天助手、在线客服、会议记 录、医患交流 等。然而长对话信息量大，关键信息容易淹没，上下文切换开销大。 例如，当我和大模型聊了一整天，形成了这么长的对话，我很难……如果能够对长对话进行梳理，我们就能……。”', '改的流畅一点：', '把下面的内容汇聚成一两句话，陈述一下：', '用一句话总结这三句话：', '总结一下这段话：', '小模型怎么 和大模型进行结合', '我可以用大模型的prompt实现小模型＋大模型的效果吗', ' 主题模型有哪些', '我想从一段长对话当中先进性小模型（主题模型）进行一个大 致的过滤，然后将过滤出来的信息再让大模型进行抽取，这样抽取效果是不是更好 一点', '小模型过滤你推荐我用那些模型', '我需要BERTopic', "ModuleNotFoundError: No module named 'bertopic'", "ImportError: cannot import name 'HDBSCAN' from 'sklearn.cluster' (D:\\anaconda\\lib\\site-packages\\sklearn\\cluster_init_.py)", 'Traceback (most recent call last):', 'Traceback (most recent call last):', 'ERROR: Could not find a version that satisfies the requirement scipy==1.10.1 (from versions: none)', 'anconda怎么创建一个虚拟环境', '我想在anaconda里面创建一个python3.11的环境', '我创建好了这个虚 拟环境，我怎么在VScode里面使用呢', 'Traceback (most recent call last):', 'vscode里面怎么更换python解释器', '我更换了解释器，但是为什么查看python版本的时候还是旧版本', 'S C:\\Users\\PC\\Desktop\\code_vis25\\long_conversation\\conversation> & D:/anaconda/envs/longconversion_env/python.exe c:/Users/PC/Desktop/code_vis25/long_conversation/conversation/bertandLLM/py/bert_test.py', 'Traceback (most recent call last):', 'Traceback (most recent call last):', 'Traceback (most recent call last):', 'Traceback (most recent call last):', "CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.", '我想删除conda里面的虚拟环境', '怎么使用bertopic，给一个完整的使用过程', '你现在了解我的设计流程了吗', ' 没错，是这个流程，你看看我大模型深度抽取这里的Prompt哪里需要修改一下', 'prompt = f"""请完成以下两个任务：', '我现在不是抽取问题，而是抽取对话的主 题和子主题', '我可以将输出结果为DST格式添加到prompt里面吗', '能不能给我个例子，以生活和工作为大主题', '昨天没休息够，好像去爬山。', '好像有个新项 目要讨论。', '现在这个prompt如何：', '所以通过这个prompt，我就可以实现从 小模型的输出中，使用LLM进行抽取，同时将输出结果转换成DST的多层次格式了吗', '现在我想实现小模型的一个对话过滤', '那我该怎么调用bertopic呢', '我没有使用虚拟环境，我使用的是python3.9.12，可以使用吗', 'Requirement already satisfied: pip in d:\\anaconda\\lib\\site-packages (25.2)', '大模型有记忆 裁剪的功能吗', '大模型API有遗忘功能吗', '介绍一下BERTopic', 'NLP领域有哪 些从长文本对话中抽取主题的论文呢', '从长对话中抽取主题的这个流程经过了哪 些发展过程', 'ValueError: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject', 'ImportError: numpy.core.multiarray failed to import', 'Traceback (most recent call last):', 'uninstall-distutils-installed-package', '我想卸载anaconda和python环境，重新下载', '我准备下载一个py3.12的miniconda', 'conda --version', '我添加在D:\\conda里面的路径', '我环境变量里面有D:\\anaconda，是之前 没删掉的吗', '我需要创建一个虚拟环境吗，不能直接使用base吗', '我在哪里创 建这些：', 'miniconda也有anaconda prompt吗', 'usage: conda-script.py [-h] [-v] [--no-plugins] [-V] COMMAND ...', 'conda activate longconversion_env', 'autoRun里面的值是：if exist', 'Traceback (most recent call last):', 'Traceback (most recent call last):', 'pip : 无法将“pip”项识别为 cmdlet、函数、脚本文件或可运行程序的名称。请', 'Traceback (most recent call last):', 'Traceback (most recent call last):', '把doc给我扩充一下：', 'from bertopic import BERTopic', '这一段没有输出：', '输出是这个：', '给我把代码 修改一下：', '现在输出是这样的：', "现在的输出结果是这样的： 主题 0: [(' 朋友请我去吃日料', np.float64(0.1997154849035994)), ('每天早上坚持做瑜伽', np.float64(0.1997154849035994)), ('最近咖啡喝太多了', np.float64(0.1997154849035994)), ('昨天去健身房举铁', np.float64(0.1997154849035994)), (' 打排球的时候扭伤了手腕', np.float64(0.1997154849035994)), ('最近在学打 羽毛球', np.float64(0.1997154849035994)), ('我昨天吃了火锅', np.float64(0.1997154849035994)), ('我准备周末去游泳', np.float64(0.1997154849035994)), ('周末打算去逛街', np.float64(0.1997154849035994)), ('天气真好', np.float64(0.1997154849035994))] 主题 1: [('python', np.float64(0.2598821953943747)), ('notebook', np.float64(0.1302492292849561)), ('jupyter', np.float64(0.1302492292849561)), ('means', np.float64(0.1302492292849561)), ('pandas', np.float64(0.1302492292849561)), ('支持向量机可以做文本分类吗', np.float64(0.1302492292849561)), ('我 想学习', np.float64(0.1302492292849561)), ('怎么安装', np.float64(0.1302492292849561)), ('快速排序适合处理大数据 吗', np.float64(0.1302492292849561)), ('如何用', np.float64(0.1302492292849561))] 我想把主题0或者1改成这个主题实际的内容，然后下面每个句子的np.float64也不用显示", '我只能手动映射吗', 'Traceback (most recent call last):', '另一个程序正在使用此文件，进程无法访问。', 'pip : 无法将“pip”项识别为 cmdlet、函数、脚本文件或可运行程序的名称。请', '我想在PATH里面加入pip', 'Traceback (most recent call last):', 'Traceback (most recent call last):', 'BERTopic能将一段对话当中的主题抽取出来吗', '我需要你帮我写个小例子', '对的，我需要你帮我把原始句子也打印出来', '这段没有输出：', '=== 主题列表 ===', 'BERTopic能够将对话当中的无关紧要的句子给过滤掉吗', '我有一段长对话，我想将这段对话当中的主题给抽取出来，同时将对话当中的无关紧要的句子给过 滤掉，有什么办法', '这个例子的输出是怎么样的', '我想句子保持一个时间顺序 ，具体来说呢句子的出现顺序不能改变', 'docs改成这个：', '为什么我的关键词 这里获取的很奇怪，(python, 我想咨询一下, 学习的方法, 那机器学习可以用, 可以用来做数 据分析吗, 你好, , , , ）', '无法解析导入“jieba”', 'Traceback (most recent call last):', '只输出了这个：', 'BERTopic的关键词抽取是怎么抽取的', '所以，BERTopic抽取出来的关键词，一定是在句子当中出现过的词吗', ' 那我不需要bertopic', '我的目标是这个：', '那你觉得BERTopic＋LLM和prompt的方法怎么样', 'BERTopic做预处理，按语义聚类，但是他不会给出这个主题的名字 ，后续还要大模型重新去判断主题的名字', '但有的时候-1的噪音类并不是没有用 处的，例如聊到天气怎么样其实也算生活类的对话', '但是其实BERTopic抽出的主 题簇还可以细分成更小的簇，LLM可以做到这些吗', '这是我的一个整体技术路线：', '现在我的想法是：将用户的对话的输入先输入到BERTopic中，然后将BERTopic 的输出再输出给LLM，最后用后端输出结果', '现在我的想法是：将用户的对话的输入先输入到BERTopic中，然后将BERTopic的输出再输出给LLM，最后从后端输出到前端，下面我分别给你代码部分', '这是从前端对话输入到后端的过程：', '这是后 端接收，同时输入到LLM，我是想输入到BERTopic中：', '这是我的BERTopic代码：', '我想把BERTopic的代码写成一个def bertopic_extraction_information', '这个返回的result是什么样的', "@app.route('/extract_question', methods=['POST'])", '我这里得到的result是经过了bertopic抽取过后的结果，就是小模型的结 果', '那我现在想将小模型的结果输入到LLM当中进行一个抽取，然后将最后抽取出来的结果再返回前端', '第三个路由 调用LLM抽取问题', '这是我的大模型抽取部 分：', '这是我的小模型聚类：', '这是我的前端往后端传入数据的部分：', '对 的，其实我只需要分析user的对话就好了', '其实我是不是可以在前端只传入user 的发言', '我采用了这种在前端过滤的方法', '你觉得最前面的那部分筛选msg的还有作用吗', '小模型的返回格式怎么调整： [ { "topic_id": 0, "keywords": ["python", "学习"], "sentences": [ "你好，我想咨询一下 Python 学习的方法", "Python 可以用来做数据分析吗？" ] }, { "topic_id": 1, "keywords": ["深度学习", "TensorFlow"], "sentences": [ "我最近在看深度学习的资料，有点难", " 深度学习可以用 TensorFlow 或者 PyTorch 来做" ] } ]', '我设定的返回格式是 ：', '筛选出来之后，我想把User：删除掉', '为什么要用两个replace', '我输出的DST格式想修改一下，这样输出可以吗：', '我不想要domains，domain存在一个 数组', '我现在大模型抽取出来的结果是这样的：', '这个slot都是通过sentences当中的句子得出来的吧', '有没有什么办法让slot和sentence一一对应，让我知道 选择了那个slot就代表了哪个句子', '我想使用方法3，你能帮我修改一下我的prompt吗', '这个输出示例是不是有问题：', 'Traceback (most recent call last):', '为什么要加这个表情😅', '正式一点', 'Traceback (most recent call last): File "c:\\Users\\PC\\Desktop\\code_vis25\\long_conversation\\LLM-long_conversation\\py\\LLM_Extraction.py", line 96, in result = llm_extract_information(content) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File "c:\\Users\\PC\\Desktop\\code_vis25\\long_conversation\\LLM-long_conversation\\py\\LLM_Extraction.py", line 64, in llm_extract_information result = json.loads(completion.choices[0].message.content) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File "D:\\conda\\envs\\longconversion_env\\Lib\\json_init_.py", line 346, in loads return _default_decoder.decode(s) ^^^^^^^^^^^^^^^^^^^^^^^^^^ File "D:\\conda\\envs\\longconversion_env\\Lib\\json\\decoder.py", line 338, in decode obj, end = self.raw_decode(s, idx=_w(s, 0).end()) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File "D:\\conda\\envs\\longconversion_env\\Lib\\json\\decoder.py", line 356, in raw_decode raise JSONDecodeError("Expecting value", s, err.value) from None json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)', '你知道d3吗', '你用d3帮我生成一个有放大效果的椭圆', 'const container = ref<HTMLElement | null>(null)', 'vue3', '我不需要按钮，我是通过鼠标滚轮实现放大', '我不能定义成一 个函数吗？', '应为声明或语句', '下面代码有错误吗', '我想设置一个计数器， 根据我输入的个数来创建矩形', '这个函数不是可以生成椭圆吗？', '可动态生成 多个椭圆且支持滚轮缩放', '我能实现一个大椭圆里面套一个小椭圆的效果吗，意 思就算说当我对大椭圆放大的时候，就可以看到大椭圆当中的小椭圆', '在大椭圆 里放多个小椭圆，实现“嵌套层级可视化”', '你还记得我的LLM抽取出来的结果吗：', '你太明白我的意思了，我想让大椭圆表示domain，小椭圆表示slot，tooltip小椭圆时显示sentence的内容', '就是一开始小椭圆是不显示的，在放大1.25倍之后 ，小椭圆才出现', '加上小椭圆渐现动画', '这是一个鼠标滚轮缩放的事件吗', ' 我的小椭圆的位置信息正确保存下来了，但是我放大的时候并没有出现', 'function drawUI() {', '每个椭圆的大小我并不想让他设置成一样大，而是根据slots里面的数量来决定大小，例如默认大椭圆为cx50，cy30，如果slots有两个slot，就设置为1.2倍，如果有三个就设置为1.4倍，具体是1+0.2*（x-1），x是slots里面的数量', ".attr('cx', centerX)", '属性“slots”在类型“{ x: number; y: number; sentence: string; slot: string; }”上不存在。你是否指的是“slot”?', 'function drawUI() {', '小椭圆大小是一定的，我控制的是大椭圆的大小', '这样，我每个 椭圆的颜色我想设置一下', '我在data里面存储每个大椭圆和小椭圆对应的颜色， 创建椭圆的时候直接使用', '我想大主题和小主题的颜色色系是相同的，大主题颜 色更深一点，例如大主题是大红色，小主题是浅红色', '一个大主题的小主题颜色 可以是一样的', '每个domain都分配一个颜色', '为啥放大不显示小椭圆：', '还 是不对，我通过debug发现是小椭圆颜色设置的问题', 'const data = [', '我现在把小椭圆的颜色也输入到data里面了：', '有什么颜色库吗，我想每个domain的颜 色都是不同的', '我在prompt里面分布颜色的时候想让他们不同：', '我抽取出来 给他加颜色：', '给我生成十个颜色色系和对应的浅色色系', '现在小椭圆在大椭 圆里面的分布是怎么设置的', '我想让他按照一行分布在大椭圆里面', '大椭圆悬 浮效果这个能够实现吗？', '小椭圆的宽度可以自己设定吗，根据大椭圆的宽度来', '宽度不应该是一半，比如有的大椭圆里面有三个小椭圆，有的有两个', '这个后端大模型抽取出来的result怎么返回前端呢', '我想用flask', '这里怎么添加颜色：', 'File "c:\\Users\\PC\\Desktop\\code_vis25\\long_conversation\\LLM-long_conversation\\py\\test.py", line 58, in colored_results = assign_colors(results)', '帮我改成自动检测domain', '这是我的输出结果，里面本身不含color', '其实我的数据是写在后端的，我只想将后端运行的结果传给前端，现在不需 要前端传给后端数据', '我现在data从后端输入，那我前端在哪里接收呢', '这样 写是对的吗', "console.log('后端返回数据:', data)", '找不到名称“async”', 'Failed to load resource: the server responded with a status of 405', "我 在进行.attr('fill', domainData.color)时，类型“string | undefined”的参数不能赋给类型“string | number | boolean | readonly (string | number)[] | ValueFn<SVGEllipseElement, unknown, string | number | boolean | readonly (string | number)[] | null> | null”的参数。", '为什么我后端返回了正确的结果 ，但是前端却没有渲染出来，是不是要添加一个watch来监听后端数据', '这里修改一下：', 'const backendData = ref<Conversation[]>([]) // 后端数据', "Uncaught (in promise) TypeError: Cannot read properties of undefined (reading 'length')", '我最终返回的结果是这样的，backendData的newVal：', 'factor高低的区别是什么', 'domain的颜色怎么调整', '最多只有10个颜色循环吗', 'import colorsys', 'Failed to load resource: the server responded with a status of 500', 'TypeError: data.flat is not a function', '这一步出错了：', '当我这样写的时候就没有报错：color_palette = plt.cm.tab10.colors', '我想自己定义一个color_palette，不再使用：', 'def lighten_color(color, factor=0.75):', 'color_palette = [', '我想增加一个判断，当只有一个小椭圆的时候，我固定小椭圆大小，当有多个小椭圆的时候，再按照下面的方法来', '只有一个小椭圆 的时候我想让它居中显示', 'Openai调用API的代码是哪些', '分别介绍一下这个代码的具体作用', 'messages=[', '调用API模型不会记得之前的对话吗', '如果我想让模型记住之前的对话，我应该怎么做', 'RAG (Retrieval-Augmented Generation)是什么', '去哪个数据库检索呢，是我自己生成的数据库吗', '介绍一下FAISS', 'FAISS怎么在本地使用', 'const ellipsesData = data.map((domainData) => {', '小椭圆我也想放在中心显示：', '为啥字体没显示：', '缩放时文字大小自适应 怎么设置', '字的位置在哪设置：', '我现在的大椭圆是在X轴分布，我想让他按照Y轴分布']

    topics_info = bertopic_extraction_information(docs=docs)

    for topic in topics_info:
        print("句子：")
        for s in topic['sentences']:
            print("-", s)
